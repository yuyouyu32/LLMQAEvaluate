{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "Labels = []\n",
    "with open('./Answers/QA.jsonl', 'r', encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        Labels.append(data['A'])\n",
    "Answers = Labels[:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 1.0, 'p': 1.0, 'f': 0.9999999949999997},\n",
       " 'rouge-2': {'r': 1.0, 'p': 1.0, 'f': 0.9999999949999997},\n",
       " 'rouge-l': {'r': 1.0, 'p': 1.0, 'f': 0.9999999949999997}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rouge import Rouge \n",
    "\n",
    "def Rouge_Score(hypothesis, reference):\n",
    "    rouger = Rouge()\n",
    "    scores = rouger.get_scores(hypothesis, reference)\n",
    "    arr_1 = np.array([[item['rouge-1']['r'], item['rouge-1']['p'], item['rouge-1']['f']] for item in scores])\n",
    "    avg_r_1, avg_p_1, avg_f_1 = np.mean(arr_1[:, 0]), np.mean(arr_1[:, 1]), np.mean(arr_1[:, 2])\n",
    "    arr_2 = np.array([[item['rouge-2']['r'], item['rouge-2']['p'], item['rouge-2']['f']] for item in scores])\n",
    "    avg_r_2, avg_p_2, avg_f_2 = np.mean(arr_2[:, 0]), np.mean(arr_2[:, 1]), np.mean(arr_2[:, 2])\n",
    "    arr_l = np.array([[item['rouge-l']['r'], item['rouge-l']['p'], item['rouge-l']['f']] for item in scores])\n",
    "    avg_r_l, avg_p_l, avg_f_l = np.mean(arr_l[:, 0]), np.mean(arr_l[:, 1]), np.mean(arr_l[:, 2])\n",
    "    avg_scores = {\n",
    "        'rouge-1': {'r': avg_r_1, 'p': avg_p_1, 'f': avg_f_1},\n",
    "        'rouge-2': {'r': avg_r_2, 'p': avg_p_2, 'f': avg_f_2}, \n",
    "        'rouge-l': {'r': avg_r_l, 'p': avg_p_l, 'f': avg_f_l}\n",
    "        }\n",
    "    return avg_scores, arr_l[:, 2]\n",
    "rouge_scores, rouge_scores_l_f1 = Rouge_Score(Answers, Labels)\n",
    "rouge_scores_l_f1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'BLEU-1': 1.0, 'BLEU-2': 1.0, 'BLEU-3': 1.0, 'BLEU-4': 1.0},\n",
       " [1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu\n",
    "\n",
    "\n",
    "def Bleu_Scores(candidates, references):\n",
    "    references  = np.array(references).reshape(-1, 1)\n",
    "    references_tokens = [[s.split() for s in sentences] for sentences in references]\n",
    "\n",
    "    candidates_tokens = [sentence.split() for sentence in candidates]\n",
    "\n",
    "    bleu_scores = [corpus_bleu(references_tokens, candidates_tokens, weights=(n,)) for n in range(1, 5)]\n",
    "    bleu_1_scores = [sentence_bleu(r, z, weights=(1,)) for r, z in zip(references_tokens, candidates_tokens)]\n",
    "    ave_scores = {}\n",
    "    for n, score in enumerate(bleu_scores, start=1):\n",
    "       ave_scores[f\"BLEU-{n}\"] = score\n",
    "    return ave_scores, bleu_1_scores\n",
    "\n",
    "Bleu_Scores(Answers, Labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. NIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'NIST-5': 11.610220208186881},\n",
       " [4.221928094887364,\n",
       "  3.807354922057605,\n",
       "  4.247927513443585,\n",
       "  3.664497779200462,\n",
       "  3.625,\n",
       "  3.807354922057605,\n",
       "  4.696131794257842,\n",
       "  4.221928094887364,\n",
       "  4.3685225277282065,\n",
       "  4.16992500144231,\n",
       "  4.058813890331199,\n",
       "  2.584962500721156,\n",
       "  4.373660689688185,\n",
       "  3.1699250014423126,\n",
       "  4.436605434317882,\n",
       "  4.0588138903312,\n",
       "  4.623516641218017,\n",
       "  4.0,\n",
       "  4.623516641218017,\n",
       "  3.875,\n",
       "  4.418295834054492,\n",
       "  4.800812842575149,\n",
       "  5.045301086491799,\n",
       "  5.087462841250338,\n",
       "  5.131556065016097,\n",
       "  5.11364956559369,\n",
       "  4.696131794257842,\n",
       "  5.271928094887366,\n",
       "  2.584962500721156,\n",
       "  2.0,\n",
       "  3.3219280948873626,\n",
       "  4.142664355548848,\n",
       "  3.3219280948873626,\n",
       "  3.807354922057605,\n",
       "  3.0,\n",
       "  3.0,\n",
       "  4.16992500144231,\n",
       "  3.664497779200462,\n",
       "  3.9698157824268114,\n",
       "  3.1699250014423126,\n",
       "  2.584962500721156,\n",
       "  3.0,\n",
       "  4.2626923908396215,\n",
       "  3.7004397181410913,\n",
       "  3.947702779220088,\n",
       "  3.807354922057605,\n",
       "  3.7946534735443405,\n",
       "  4.8125,\n",
       "  2.584962500721156,\n",
       "  4.825164052322358,\n",
       "  4.675698135367987,\n",
       "  3.0,\n",
       "  3.1699250014423126,\n",
       "  3.3219280948873626,\n",
       "  4.3219280948873635,\n",
       "  4.593069207771888,\n",
       "  3.947702779220089,\n",
       "  3.852168723603281,\n",
       "  4.601409765557392,\n",
       "  3.807354922057605,\n",
       "  4.297079327540665,\n",
       "  4.680813428089396,\n",
       "  4.556088322639178,\n",
       "  4.681727678869736,\n",
       "  4.316827716832513,\n",
       "  3.9754180179138334,\n",
       "  4.247927513443585,\n",
       "  4.54659356429494,\n",
       "  4.450212064914746,\n",
       "  4.843568731230678,\n",
       "  3.41829583405449,\n",
       "  4.121928094887364,\n",
       "  5.016088589983934,\n",
       "  2.321928094887362,\n",
       "  3.584962500721156,\n",
       "  3.7345216647797526,\n",
       "  3.906890595608518,\n",
       "  4.0,\n",
       "  4.546593564294939,\n",
       "  4.363713275750191,\n",
       "  4.0,\n",
       "  4.221928094887364,\n",
       "  4.384517131793099,\n",
       "  4.506890595608518,\n",
       "  4.6150610122030695,\n",
       "  4.606739354015321,\n",
       "  4.563856189774724,\n",
       "  4.779094498080775,\n",
       "  4.625053839880557,\n",
       "  3.5465935642949376,\n",
       "  4.037401197654112,\n",
       "  2.8073549220576046,\n",
       "  3.3927474104487843,\n",
       "  3.1699250014423126,\n",
       "  4.021928094887363,\n",
       "  3.807354922057605,\n",
       "  3.584962500721156,\n",
       "  3.7735572622751845,\n",
       "  3.98418371977919,\n",
       "  4.293660689688185,\n",
       "  4.436605434317882,\n",
       "  4.373557262275184,\n",
       "  4.121928094887364,\n",
       "  4.30350885479768,\n",
       "  3.3346791410515944,\n",
       "  4.840223928941852,\n",
       "  4.349648912578751,\n",
       "  4.0,\n",
       "  4.152391277629866,\n",
       "  4.0,\n",
       "  4.247927513443585,\n",
       "  3.807354922057605,\n",
       "  4.262692390839621,\n",
       "  4.121928094887364,\n",
       "  4.436605434317882,\n",
       "  4.087462841250341,\n",
       "  4.277613436819116,\n",
       "  4.954196310386873,\n",
       "  4.297079327540665,\n",
       "  4.829966150010237,\n",
       "  4.73592635062903,\n",
       "  4.165894208390024,\n",
       "  3.584962500721156,\n",
       "  3.0,\n",
       "  3.807354922057605,\n",
       "  3.906890595608518,\n",
       "  3.906890595608518,\n",
       "  4.121928094887364,\n",
       "  3.459431618637297,\n",
       "  3.7735572622751845,\n",
       "  4.087462841250341,\n",
       "  3.5216406363433186,\n",
       "  4.532665279941248,\n",
       "  3.277613436819115,\n",
       "  3.852168723603281,\n",
       "  3.0,\n",
       "  4.3685225277282065,\n",
       "  4.087462841250341,\n",
       "  4.087462841250341,\n",
       "  4.563856189774724,\n",
       "  3.906890595608518,\n",
       "  4.2626923908396215,\n",
       "  3.906890595608518,\n",
       "  4.297079327540665,\n",
       "  4.984769618706743,\n",
       "  4.569532239061021,\n",
       "  4.037401197654112,\n",
       "  4.373660689688185])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.translate.nist_score import corpus_nist, sentence_nist\n",
    "\n",
    "def Nist_Scores(candidates, references):\n",
    "    references  = np.array(references).reshape(-1, 1)\n",
    "    references_tokens = [[s.split() for s in sentences] for sentences in references]\n",
    "    \n",
    "    candidates_tokens = [sentence.split() for sentence in candidates]\n",
    "\n",
    "    nist_5 = corpus_nist(references_tokens, candidates_tokens, n=5)\n",
    "\n",
    "    nist_5_scores = [sentence_nist(r, z, n=min(len(r), 5)) for r, z in zip(references_tokens, candidates_tokens)]\n",
    "\n",
    "    return nist_5 , nist_5_scores\n",
    "\n",
    "Nist_Scores(Answers, Labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Meteor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'METEOR': 0.999705915324945},\n",
       " [0.9999375,\n",
       "  0.9998177842565598,\n",
       "  0.9999271030762502,\n",
       "  0.9998177842565598,\n",
       "  0.9998779296875,\n",
       "  0.9998177842565598,\n",
       "  0.9999832164076399,\n",
       "  0.9999375,\n",
       "  0.9999530428249437,\n",
       "  0.9999142661179699,\n",
       "  0.9999142661179699,\n",
       "  0.9976851851851852,\n",
       "  0.999968,\n",
       "  0.9993141289437586,\n",
       "  0.999958905235473,\n",
       "  0.9999142661179699,\n",
       "  0.9999715521165226,\n",
       "  0.9998779296875,\n",
       "  0.9999715521165226,\n",
       "  0.9998779296875,\n",
       "  0.9999638310185185,\n",
       "  0.9999832164076399,\n",
       "  0.9999948631544341,\n",
       "  0.9999872786484836,\n",
       "  0.9999915709974881,\n",
       "  0.9999927453171021,\n",
       "  0.9999832164076399,\n",
       "  0.9999921875,\n",
       "  0.9976851851851852,\n",
       "  0.9921875,\n",
       "  0.9995,\n",
       "  0.9999271030762502,\n",
       "  0.9995,\n",
       "  0.9998177842565598,\n",
       "  0.9990234375,\n",
       "  0.9990234375,\n",
       "  0.9999142661179699,\n",
       "  0.9998177842565598,\n",
       "  0.999898229187869,\n",
       "  0.9993141289437586,\n",
       "  0.9976851851851852,\n",
       "  0.9990234375,\n",
       "  0.999958905235473,\n",
       "  0.9997724169321802,\n",
       "  0.9999142661179699,\n",
       "  0.9998177842565598,\n",
       "  0.9999142661179699,\n",
       "  0.9999847412109375,\n",
       "  0.9976851851851852,\n",
       "  0.9999832164076399,\n",
       "  0.9999872786484836,\n",
       "  0.9990234375,\n",
       "  0.9993141289437586,\n",
       "  0.9995,\n",
       "  0.9999375,\n",
       "  0.9999772230320699,\n",
       "  0.9999142661179699,\n",
       "  0.999898229187869,\n",
       "  0.9999847412109375,\n",
       "  0.9998177842565598,\n",
       "  0.9999460101500918,\n",
       "  0.9999745973682873,\n",
       "  0.9999794989544467,\n",
       "  0.9999814814814815,\n",
       "  0.999958905235473,\n",
       "  0.9999460101500918,\n",
       "  0.9999271030762502,\n",
       "  0.9999715521165226,\n",
       "  0.9999772230320699,\n",
       "  0.9999883381924198,\n",
       "  0.9997106481481481,\n",
       "  0.9999375,\n",
       "  0.9999927453171021,\n",
       "  0.996,\n",
       "  0.9997106481481481,\n",
       "  0.999898229187869,\n",
       "  0.9998518518518519,\n",
       "  0.9998779296875,\n",
       "  0.9999715521165226,\n",
       "  0.9999715521165226,\n",
       "  0.9998779296875,\n",
       "  0.9999375,\n",
       "  0.9999745973682873,\n",
       "  0.9999814814814815,\n",
       "  0.9999814814814815,\n",
       "  0.9999745973682873,\n",
       "  0.999968,\n",
       "  0.9999860867629463,\n",
       "  0.9999794989544467,\n",
       "  0.9997724169321802,\n",
       "  0.9999271030762502,\n",
       "  0.9985422740524781,\n",
       "  0.9997724169321802,\n",
       "  0.9993141289437586,\n",
       "  0.9999375,\n",
       "  0.9998177842565598,\n",
       "  0.9997106481481481,\n",
       "  0.9998518518518519,\n",
       "  0.9999375,\n",
       "  0.999968,\n",
       "  0.999958905235473,\n",
       "  0.9999814814814815,\n",
       "  0.9999375,\n",
       "  0.9999638310185185,\n",
       "  0.9997724169321802,\n",
       "  0.9999814814814815,\n",
       "  0.999958905235473,\n",
       "  0.9998779296875,\n",
       "  0.9999530428249437,\n",
       "  0.9998779296875,\n",
       "  0.9999271030762502,\n",
       "  0.9998177842565598,\n",
       "  0.999958905235473,\n",
       "  0.9999375,\n",
       "  0.999958905235473,\n",
       "  0.999898229187869,\n",
       "  0.9999530428249437,\n",
       "  0.9999832164076399,\n",
       "  0.9999460101500918,\n",
       "  0.9999872786484836,\n",
       "  0.9999772230320699,\n",
       "  0.9999460101500918,\n",
       "  0.9997106481481481,\n",
       "  0.9990234375,\n",
       "  0.9998177842565598,\n",
       "  0.9998518518518519,\n",
       "  0.9998518518518519,\n",
       "  0.9999375,\n",
       "  0.9996243425995492,\n",
       "  0.9998518518518519,\n",
       "  0.999898229187869,\n",
       "  0.9998177842565598,\n",
       "  0.9999745973682873,\n",
       "  0.9996243425995492,\n",
       "  0.999898229187869,\n",
       "  0.9990234375,\n",
       "  0.9999530428249437,\n",
       "  0.999898229187869,\n",
       "  0.999898229187869,\n",
       "  0.999968,\n",
       "  0.9998518518518519,\n",
       "  0.999958905235473,\n",
       "  0.9998518518518519,\n",
       "  0.9999460101500918,\n",
       "  0.9999908878845313,\n",
       "  0.9999872786484836,\n",
       "  0.9999271030762502,\n",
       "  0.999968])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.translate.meteor_score import meteor_score\n",
    "\n",
    "def Meteor_Scores(candidates, references):\n",
    "    references  = np.array(references).reshape(-1, 1)\n",
    "    references_tokens = [[s.split() for s in sentences] for sentences in references]\n",
    "\n",
    "    candidates_tokens = [sentence.split() for sentence in candidates]\n",
    "\n",
    "    meteor_scores = [meteor_score(ref, candidate) for ref, candidate in zip(references_tokens, candidates_tokens)]\n",
    "    return np.mean(meteor_scores).item(), meteor_scores\n",
    "\n",
    "Meteor_Scores(Answers, Labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Bert Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at D:\\yuyouyu\\CODE\\QA_Evaluate\\models--roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2238ac9c8d34a9a8c2a322c8a8c08a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f96dd195152a4a4da1d5047d196a4fcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.29 seconds, 502.63 sentences/sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'BERT-P:': 1.0, 'BERT-R:': 1.0, 'BERT-F1:': 1.0},\n",
       " array([1.        , 1.0000002 , 1.        , 1.        , 0.9999997 ,\n",
       "        0.99999994, 1.        , 1.        , 0.9999999 , 1.        ,\n",
       "        1.        , 1.0000001 , 0.9999999 , 0.99999994, 1.        ,\n",
       "        1.        , 1.        , 0.99999994, 0.9999999 , 1.        ,\n",
       "        0.99999994, 0.9999999 , 1.        , 0.99999994, 0.9999999 ,\n",
       "        1.0000001 , 1.        , 1.        , 0.99999994, 1.        ,\n",
       "        1.0000001 , 1.        , 1.0000002 , 0.9999999 , 0.99999976,\n",
       "        0.9999999 , 0.9999999 , 1.        , 1.        , 1.0000001 ,\n",
       "        0.9999998 , 1.0000001 , 0.9999999 , 1.        , 1.0000001 ,\n",
       "        1.0000001 , 0.9999999 , 1.        , 1.0000001 , 0.9999999 ,\n",
       "        1.        , 1.        , 1.0000001 , 1.        , 1.        ,\n",
       "        0.99999994, 0.9999999 , 1.        , 0.9999999 , 1.        ,\n",
       "        1.        , 1.0000002 , 0.99999994, 1.        , 0.99999994,\n",
       "        1.        , 0.99999994, 0.99999994, 1.        , 0.9999999 ,\n",
       "        1.        , 0.9999999 , 1.        , 1.        , 0.9999999 ,\n",
       "        1.        , 0.9999999 , 0.9999998 , 0.99999994, 1.        ,\n",
       "        1.        , 0.99999994, 0.99999994, 0.99999994, 0.99999994,\n",
       "        1.        , 1.        , 0.99999994, 1.        , 1.0000001 ,\n",
       "        0.99999994, 1.0000002 , 1.0000001 , 0.99999976, 1.        ,\n",
       "        0.9999999 , 1.        , 1.        , 1.        , 0.99999994,\n",
       "        0.99999994, 1.        , 1.        , 1.        , 1.0000001 ,\n",
       "        0.99999994, 1.        , 0.9999999 , 1.        , 1.        ,\n",
       "        1.        , 0.99999994, 1.        , 0.9999999 , 1.        ,\n",
       "        1.        , 1.        , 0.9999999 , 1.        , 1.0000001 ,\n",
       "        1.        , 0.9999999 , 0.99999994, 1.0000002 , 0.99999994,\n",
       "        0.9999999 , 1.        , 0.99999994, 0.9999999 , 1.0000001 ,\n",
       "        0.99999994, 0.99999994, 0.9999999 , 1.0000001 , 0.99999994,\n",
       "        1.0000001 , 1.        , 1.        , 1.        , 0.9999998 ,\n",
       "        0.99999994, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.0000001 , 1.        , 1.        ], dtype=float32))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "\n",
    "def Bert_Score(candidates, references):\n",
    "\n",
    "    P, R, F1 = score(candidates, references, model_type=\"roberta-large\", verbose=False)\n",
    "\n",
    "    return {\"BERT-P:\": float(np.mean(P.numpy())), \"BERT-R:\": float(np.mean(R.numpy())), \"BERT-F1:\": float(np.mean(F1.numpy()))}, F1.numpy()\n",
    "\n",
    "Bert_Score(Answers, Labels)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.Cider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10.0,\n",
       " array([10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10.,\n",
       "        10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10.,\n",
       "        10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10.,\n",
       "        10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10.,\n",
       "        10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10.,\n",
       "        10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10.,\n",
       "        10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10.,\n",
       "        10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10.,\n",
       "        10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10.,\n",
       "        10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10.,\n",
       "        10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10.,\n",
       "        10., 10., 10., 10., 10.]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pycocoevalcap.cider.cider import Cider\n",
    "\n",
    "def Cider_Score(candidates, references):\n",
    "\n",
    "    candidates = {i: [sentence] for i, sentence in enumerate(candidates)}\n",
    "    references = {i: [sentence] for i, sentence in enumerate(references)}\n",
    "    cider_scorer = Cider()\n",
    "    # 计算CIDEr分数\n",
    "    ave_score, scores = cider_scorer.compute_score(candidates, references)\n",
    "    return ave_score.item(), scores\n",
    "\n",
    "Cider_Score(Answers, Labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
